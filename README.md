# Knowledge Distillation
## All you need to do for achieving competitive SOTA results in Knowledge Distillation like CRD, ReviewKD, Decoupled KD, is to construct MSE loss for the last conv output and tune the coefficient of the loss.

## That is to say, FitNet (2015) can be as good as these recent works. 
